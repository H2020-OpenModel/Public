{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "This example demonstrates:\n",
    "- how ExecFlow can be used to run an executable for which there has not been created a dedicated aiida-plugin \n",
    "- how to document your data (both existing and desired) with DLite models and partial pipelines\n",
    "- how combined partial pipelines can be used to generate a desired input with the use of mappings (to and ontology)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"demo_figures/samtale1.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Eventually it will be possible to ask the OpenModel OIP to create a workflow based on the the knowledge it has from the ontologies and what data it has access to.\n",
    "This is done by OntoFlow. \n",
    "\n",
    "The output of OntoFlow will be a workflow description and for our current work flow this will be something like this schematically:\n",
    "\n",
    "<img src=\"demo_figures/full_workflow.png\" alt=\"drawing\" width=\"1000\"/>\n",
    "\n",
    "Each purple arrow-box is a step in the Declarative workchain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declarative Workchain ##\n",
    "\n",
    "This is the description of the workflow to be executed by ExecFlow. It contains several steps.\n",
    "\n",
    "1. The first and the last step are steps that make use of oteapi and documentation of data to retrieve data from data sources (first step) or put data into a data sink (last step).\n",
    "\n",
    "1. The three middle arrows are separate calculations that are intimately connected and therefore the output from one goes directly into input to the next step, without going through the interoperability layer.\n",
    "\n",
    "The declarative workchain describes the workflow and consists of the following steps:\n",
    "\n",
    "```yaml\n",
    "steps:\n",
    "  - workflow: execflow.oteapipipeline    # Run the pipeline that fetches data and generates the correct input\n",
    "    ....\n",
    "  - workflow: execflow.exec_wrapper      # Run the pre-processing tool, this is an executable that does not have an AiiDA plugin (Moltemplate)\n",
    "    ....\n",
    "  - workflow: execflow.exec_wrapper      # Run the MD simulation, this is an executable that does not have an AiiDA plugin (lammps)\n",
    "    ...\n",
    "  - calcjob: execflowdemo.lammps.density # Run a the post-processor, this is has an aiida plugin/calcjob\n",
    "    ...\n",
    "  - workflow: execflow.oteapipipeline    # Run tha pipeline that documents the generated data and sends it to a data sink\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Partial pipelines to document data ##\n",
    "\n",
    "<img src=\"demo_figures/step1.drawio.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Data is documented with the use of Partial pipelines which contain information about\n",
    "1. where the data can be retrieved (path/database)\n",
    "1. how it can be retrieved \n",
    "1. how it should be parsed \n",
    "1. which data model to parse it into\n",
    "1. the mappings of the properties in the datamodel to the correct ontology\n",
    "\n",
    "Steps 1.-4. are contained in an oteapi strategi that combines download and parsing:\n",
    "\n",
    "```yaml\n",
    "  - dataresource: name_of_choice\n",
    "    downloadUrl: \"path/to/file\"\n",
    "    mediaType: what_kind_of_file # This is is the mediaType that is registered in oteapi, each strategy in oteapi is registered with a \"type\".\n",
    "    configuration:\n",
    "      metadata: iri_of_datamodel\n",
    "      excel_config:\n",
    "        worksheet: \"SimulationParameters\"\n",
    "        header_row: \"1\"\n",
    "        row_from: \"2\"\n",
    "        row_to: \"2\"\n",
    "      label: moltemplate_input_2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first start with documenting one of our data sources, which in this specific case is just the specification of the simulation parameters, and can be found in an excel workbook called `multidata_moltemplateinput.xslx` and the work sheet `PhysicalParameters` as shown below:\n",
    "\n",
    "\n",
    "![SimulationParametersExcel](demo_figures/SimulationParametersExcel.png)\n",
    "\n",
    "Steps 1.-4. above are contained in an oteapi strategy that combines download and parsing:\n",
    "\n",
    "```yaml\n",
    "  - dataresource: load_data # name of this specific strategy with configuration, to be used locally\n",
    "    downloadUrl: \"file:///tmp/Public/Ontotrans2ndWorkshop/data/multidata_moltemplateinput.xlsx\" \n",
    "    mediaType: application/vnd.dlite-xlsx # name of oteapi strategy (plugin) to use\n",
    "    configuration:\n",
    "      metadata: http://openmodel.eu/meta/0.1/MoltemplateInputSimulationParameters # name of datamodel\n",
    "      excel_config: # Configuration for this specific oteapi strategy\n",
    "        worksheet: \"SimulationParameters\"\n",
    "        header_row: \"1\"\n",
    "        row_from: \"2\"\n",
    "        row_to: \"2\"\n",
    "      label: moltemplate_input_2\n",
    "```\n",
    "\n",
    "The data model needs to be available and in our case it looks like this:\n",
    "\n",
    "```yaml\n",
    "{\n",
    "    \"uri\": \"http://openmodel.eu/meta/0.1/MoltemplateInputSimulationParameters\",\n",
    "    \"description\": \"Entity describing input variables for the simulation\",\n",
    "    \"dimensions\": {\n",
    "        \"nrows\": \"Number of elements (i.e. number or rows).\"\n",
    "    },\n",
    "    \"properties\": {\n",
    "        \"number_of_steps\": {\n",
    "            \"type\": \"int\",\n",
    "            \"description\": \"Number of steps for something.\",\n",
    "            \"shape\": [\"nrows\"]\n",
    "        },\n",
    "        \"equilibration_steps\": {\n",
    "            \"type\": \"int\",\n",
    "            \"description\": \"Number of steps during equilibration.\",\n",
    "            \"shape\": [\"nrows\"]\n",
    "        },\n",
    "        \"s_\": {\n",
    "            \"type\": \"int\",\n",
    "            \"description\": \"Not sure.\",\n",
    "            \"shape\": [\"nrows\"]\n",
    "        },\n",
    "        \"production_steps\": {\n",
    "            \"type\": \"int\",\n",
    "            \"description\": \"Production steps.\",\n",
    "            \"shape\": [\"nrows\"]\n",
    "        },\n",
    "        \"timestep\": {\n",
    "            \"type\": \"int\",\n",
    "            \"description\": \"Time step in fs.\",\n",
    "            \"shape\": [\"nrows\"]\n",
    "        },\n",
    "        \"gridsize\": {\n",
    "            \"type\": \"int\",\n",
    "            \"description\": \"Grid size.\",\n",
    "            \"shape\": [\"nrows\"]\n",
    "        },\n",
    "       \"gridspacing\": {\n",
    "            \"type\": \"float\",\n",
    "            \"description\": \"Grid spacing.\",\n",
    "            \"shape\": [\"nrows\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will fetch the data and parse it to a datamodel, but to reach interoperability the concepts in the datamodel need to be translated to a common language that we have agreed on.\n",
    "This is done in a mapping strategy in the partial pipeline:\n",
    "```yaml\n",
    " - mapping: mappings_1\n",
    "    mappingType: mappings\n",
    "    prefixes:\n",
    "      emmo: http://emmo.info/emmo#\n",
    "      map: http://emmo.info/domain-mappings#\n",
    "      param: http://openmodel.eu/meta/0.1/MoltemplateInputSimulationParameters#\n",
    "      demonto: http://openmodel.eu/0.1/domainonto#\n",
    "    triples:\n",
    "      - [\"param:number_of_steps\", \"map:mapsTo\", \"demonto:Steps\"]\n",
    "      - [\"param:equilibration_steps\", \"map:mapsTo\", \"demonto:StepsToEquilibration\"]\n",
    "      - [\"param:s_\", \"map:mapsTo\", \"demonto:S\"]\n",
    "      - [\"param:timestep\", \"map:mapsTo\", \"demonto:TimeStep\"]\n",
    "      - [\"param:production_steps\", \"map:mapsTo\", \"demonto:StepsInProduction\"]\n",
    "      - [\"param:gridsize\", \"map:mapsTo\", \"demonto:GridSize\"]\n",
    "      - [\"param:gridspacing\", \"map:mapsTo\", \"demonto:GridSpacing\"]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oteapienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
